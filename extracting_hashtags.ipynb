{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('./train_E6oV3lV.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_hashtags = []\n",
    "for tweet in df[df['label']==0]['tweet']:\n",
    "    regex_list = re.findall(\"#(\\w+)\",tweet)\n",
    "    pos_hashtags = pos_hashtags + regex_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_hashtags = []\n",
    "for tweet in df[df['label']==1]['tweet']:\n",
    "    regex_list = re.findall(\"#(\\w+)\",tweet)\n",
    "    neg_hashtags = neg_hashtags + regex_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_hashtags = pos_hashtags + neg_hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a frequency distribution of Hashtags\n",
    "Instead of TF-IDF this could be used as coefficients for hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "pos_hash_dict = nltk.FreqDist(pos_hashtags)\n",
    "neg_hash_dict = nltk.FreqDist(neg_hashtags)\n",
    "\n",
    "for x in pos_hash_dict:\n",
    "    pos_hash_dict[x] = pos_hash_dict[x]/float(len(pos_hashtags))\n",
    "for x in neg_hash_dict:\n",
    "    neg_hash_dict[x] = neg_hash_dict[x]/float(len(neg_hashtags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a word2vec model using gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\n",
      "17813it [00:00, 176789.38it/s]\n",
      "36853it [00:00, 180289.03it/s]\n",
      "54901it [00:00, 180300.07it/s]\n",
      "66879it [00:00, 116575.66it/s]\n",
      "76296it [00:00, 141577.81it/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(161615, 381480)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from tqdm import tqdm\n",
    "LabeledSentence = gensim.models.doc2vec.LabeledSentence\n",
    "\n",
    "def labelizeTweets(tweets, label_type):\n",
    "    labelized = []\n",
    "    for i,v in tqdm(enumerate(tweets)):\n",
    "        label = '%s_%s'%(label_type,i)\n",
    "        labelized.append(LabeledSentence(v, [label]))\n",
    "    return labelized;\n",
    "\n",
    "hashtags_train = labelizeTweets(Total_hashtags, 'TRAIN')\n",
    "\n",
    "model = Word2Vec(size=100 , min_count=10)\n",
    "model.build_vocab([[x] for x in Total_hashtags])\n",
    "model.train([[x] for x in Total_hashtags], total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('musicvideo', 0.3074302077293396),\n",
       " ('instadaily', 0.3038012385368347),\n",
       " ('flagday', 0.2752704620361328),\n",
       " ('namaste', 0.2631492614746094),\n",
       " ('youtuber', 0.2532731294631958),\n",
       " ('enteainment', 0.2512967586517334),\n",
       " ('xoxo', 0.24863505363464355),\n",
       " ('tears', 0.24853824079036713),\n",
       " ('boy', 0.23527175188064575),\n",
       " ('podcast', 0.23180250823497772)]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive='enjoy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.4706900e-03,  2.0637142e-03, -1.9378130e-03, -4.0441374e-03,\n",
       "        1.8650873e-03,  1.5402967e-03, -1.5719584e-03, -4.2860387e-03,\n",
       "       -6.2611463e-05, -2.2159289e-03,  4.8616836e-03,  4.7988533e-03,\n",
       "       -3.8754351e-03,  1.4601762e-03, -1.9828053e-03,  1.2110966e-04,\n",
       "       -4.4379854e-03,  4.5729633e-03, -1.4927547e-03,  4.7749178e-03,\n",
       "        3.8615107e-03,  2.1454906e-03, -1.0454686e-03,  3.8459681e-03,\n",
       "       -2.9177987e-03, -2.1215116e-03,  1.8458575e-03, -3.1540061e-03,\n",
       "       -2.8406165e-03, -3.5182209e-04, -2.6022394e-03, -4.7477777e-03,\n",
       "        4.0419381e-03, -1.3249054e-03, -3.2001098e-03,  2.7428924e-03,\n",
       "       -4.0643991e-04, -5.5177539e-04,  2.3338906e-03,  4.4600298e-03,\n",
       "        1.7404994e-03,  2.2918819e-03,  3.2997413e-03,  1.8202115e-03,\n",
       "        4.2250315e-03, -4.8950124e-03,  4.9957205e-03, -8.8936424e-05,\n",
       "        4.9798172e-03,  2.2057013e-03,  1.3037844e-03, -1.7273304e-03,\n",
       "        3.6400722e-03, -4.9177213e-03, -3.1147045e-04,  2.5854004e-03,\n",
       "        2.0013808e-03,  3.1545421e-03, -5.7448487e-04,  3.2036686e-03,\n",
       "        1.3055597e-03, -4.4008526e-03, -2.5603864e-03, -4.8916293e-03,\n",
       "       -2.2352238e-03, -2.9440918e-03, -3.8851397e-03,  2.6925283e-03,\n",
       "       -4.5790966e-03,  3.6698552e-03, -1.3176001e-03, -3.8065787e-03,\n",
       "        5.5441895e-04,  3.7593051e-04, -4.7061360e-05, -4.1055409e-03,\n",
       "       -2.7349857e-03,  3.8337929e-04,  4.8767757e-03,  2.3166619e-03,\n",
       "        3.1418826e-03,  3.6021392e-03, -8.8645989e-04, -3.7767864e-03,\n",
       "       -1.8512052e-03, -3.5879430e-03, -4.4207410e-03,  4.1264482e-03,\n",
       "       -4.4763610e-03,  2.7274489e-03,  2.7760740e-03,  2.4319950e-03,\n",
       "       -4.3769875e-03,  2.1812764e-03,  1.1619051e-03, -4.6076430e-03,\n",
       "        1.8050409e-03,  3.9392076e-03, -3.0045351e-03, -2.5390722e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['enjoy']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
